{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "config = dotenv_values(\"../.env\")  # config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n",
    "debug_server = config['DEBUG_SERVER']\n",
    "token = config['TOKEN']\n",
    "submitt_url = config['DEBUG_SERVER_SUBMIT']\n",
    "HEADER = {'content-type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(text):\n",
    "   \"\"\" Removes all whitespaces from a given text.\"\"\"\n",
    "   return \" \".join(text.split())\n",
    "\n",
    "def remove_URLs(text):\n",
    "   \"Remove URLs from text using regular expressions.\"\n",
    "   url_re = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "   return url_re.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "   tokenizer = RegexpTokenizer(r'\\w+')\n",
    "   no_punct = tokenizer.tokenize(\" \".join(text))\n",
    "   return no_punct\n",
    "\n",
    "def remove_stopwords(text):\n",
    "   \"\"\"Removes english stopwords.\"\"\"\n",
    "   result = []\n",
    "   for token in text:\n",
    "      if token not in en_stopwords:\n",
    "         result.append(token)\n",
    "\n",
    "   return result\n",
    "\n",
    "def stemming(text):\n",
    "   porter = PorterStemmer()\n",
    "   result = []\n",
    "   for word in text:\n",
    "      result.append(porter.stem(word))\n",
    "\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_text_processing(text):\n",
    "    text = text.lower()\n",
    "    text = remove_whitespace(text)\n",
    "    text = remove_URLs(text)\n",
    "    text = word_tokenize(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "\n",
    "def ml_predict_pipeline(text, path):\n",
    "    text = ml_text_processing(text)\n",
    "    loaded_model = pickle.load(open(path, 'rb'))\n",
    "    return loaded_model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world how are you?\"\n",
    "path = \"../models/ml_models/m1_LR_CV.sav\"\n",
    "model = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world']\n"
     ]
    }
   ],
   "source": [
    "p_text = ml_text_processing(text)\n",
    "print(p_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py:787\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=785'>786</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=786'>787</a>\u001b[0m     array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=787'>788</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'hello'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tudor/projects/erisk/src/submissions.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tudor/projects/erisk/src/submissions.ipynb#ch0000016?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray([p_text]))\n",
      "File \u001b[0;32m~/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=410'>411</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=411'>412</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=412'>413</a>\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=413'>414</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=422'>423</a>\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=423'>424</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=424'>425</a>\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=425'>426</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=426'>427</a>\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=386'>387</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=387'>388</a>\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=388'>389</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=402'>403</a>\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=403'>404</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=404'>405</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=406'>407</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=407'>408</a>\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/linear_model/_base.py?line=408'>409</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py:789\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=786'>787</a>\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=787'>788</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=788'>789</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=789'>790</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to convert array of bytes/strings \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=790'>791</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minto decimal numbers with dtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=791'>792</a>\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=792'>793</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    <a href='file:///home/tudor/.mamba/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'"
     ]
    }
   ],
   "source": [
    "model.predict(np.array([p_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import DataModule\n",
    "from models import Transformer\n",
    "from transformers import RobertaTokenizerFast\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_path = r\"../models/transformer/model_val_loss0.28.ckpt\"\n",
    "tokenizer_path =  r\"../models/roberta-tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file ../models/roberta-tokenizer/config.json not found\n",
      "file ../models/roberta-tokenizer/config.json not found\n"
     ]
    }
   ],
   "source": [
    "system1 = Transformer(\n",
    "    ntokens=30000,\n",
    "    emsize=128,\n",
    "    d_hid=128,\n",
    "    nlayers=1,\n",
    "    nhead=2,\n",
    "    dropout=0.2,\n",
    ").load_from_checkpoint(model_path)\n",
    "system1.eval()\n",
    "system1_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    text = system1_tokenizer.encode_plus(\n",
    "    text,\n",
    "    # add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=False,\n",
    "    truncation=True,\n",
    "    )\n",
    "    output = torch.sigmoid(system1(text['input_ids'])).detach().numpy()\n",
    "    return np.heaviside(output, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "```\n",
    "getWritings\n",
    "while request not empty:\n",
    "    for run in runs:\n",
    "        POST request\n",
    "    getWritings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "GET_URL = 'http://127.0.0.1:5000'\n",
    "systems = [get_prediction, None, None, None, None]\n",
    "ans = requests.get(GET_URL)\n",
    "ans_dict = json.loads(ans.text)\n",
    "while ans_dict != []:\n",
    "    for run, system in enumerate(systems):\n",
    "        post_url = config['T1_SUBMISSION'] + token + \"/\" + str(run)\n",
    "        submission = []\n",
    "        for ans in ans_dict:\n",
    "            nick = ans['nick']\n",
    "            text = ans['content']\n",
    "            submission.append({\n",
    "                'nick': nick,\n",
    "                'decision': system(text),\n",
    "                'score': round(random.uniform(0,4),1)\n",
    "            })\n",
    "        post_request = requests.post(post_url, data = json.dumps(submission), headers = HEADER)\n",
    "    ans = requests.get(GET_URL)\n",
    "    ans_dict = json.loads(ans.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc7067ad0587ee2533d0568fff1e23349b43564da49d2e99835e9871e4935780"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
